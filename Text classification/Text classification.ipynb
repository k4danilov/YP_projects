{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-данных-и-первичный-осмотр\" data-toc-modified-id=\"Загрузка-данных-и-первичный-осмотр-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Загрузка данных и первичный осмотр</a></span></li><li><span><a href=\"#Лемматизация-и-токенизация-текста\" data-toc-modified-id=\"Лемматизация-и-токенизация-текста-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Лемматизация и токенизация текста</a></span></li><li><span><a href=\"#Дисбаланс-классов\" data-toc-modified-id=\"Дисбаланс-классов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Дисбаланс классов</a></span></li><li><span><a href=\"#Разделение-на-признаки-и-целевой-признак\" data-toc-modified-id=\"Разделение-на-признаки-и-целевой-признак-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Разделение на признаки и целевой признак</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Создание-корпуса-текстов-и-учет-стоп-слов\" data-toc-modified-id=\"Создание-корпуса-текстов-и-учет-стоп-слов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Создание корпуса текстов и учет стоп-слов</a></span></li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Linear Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Выбор-лучшей-модели\" data-toc-modified-id=\"Выбор-лучшей-модели-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Выбор лучшей модели</a></span></li></ul></li><li><span><a href=\"#Проверка-лучшей-модели-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-лучшей-модели-на-тестовой-выборке-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Проверка лучшей модели на тестовой выборке</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "В вашем распоряжении набор данных с разметкой о токсичности правок.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель проект:**\n",
    "- Обучить модель классифицировать комментарии на позитивные и негативные. Метрика качества *F1* должна быть не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задачи проекта:**\n",
    "- Загрузить и подготовить данные.\n",
    "- Обучить разные модели. \n",
    "- Выбрать наилучшую модель и сформулировать вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Кирилл\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Кирилл\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Кирилл\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Кирилл\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных и первичный осмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159292"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 0'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем ненужный столбец Unnamed\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** В датасете представлено около 160 тыс. строк с различными описаниями товаров. Пропуски отсутствуют. В связи с ненадобностью, удален столбец, который повторяет столбец с индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация и токенизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on their foot for good'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy lemmatizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "doc = nlp(sentence)\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_spacy(text):\n",
    "    clear_text = nlp(\" \".join(re.sub(r'[^a-zA-z]', ' ', text).split()))\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in clear_text])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2629d579b26e4b34ae781f8b3c86671c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['lemmatized_text'] = df['text'].progress_apply(lemm_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Правильная лемматизация длится долго... Минут 20-30, в зависимости от мощности компьютера. Гораздо комфортнее видеть прогресс выполнения этой длительной операции, чем сидеть и гадать \"а не зависла ли она\", \"закончит только к утру или через 30 секунд\"? Можно воспользоваться прогресс -баром от tqdm.\n",
    "    \n",
    "     \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "\n",
    "    data['lemm_text'] = data['text'].progress_apply(lemmafunction)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Добавил визуальный прогресс. Спасибо за новую фичу, не знал про функцию progress_apply\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> 🤝 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulation from I as well use the tool wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>COCKSUCKER before you pis around on MY work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the Matt Shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word nonsense be offensive to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  Explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour I m seem...  \n",
       "2  hey man I m really not try to edit war it s ju...  \n",
       "3  More I can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  \n",
       "5  congratulation from I as well use the tool wel...  \n",
       "6        COCKSUCKER before you pis around on MY work  \n",
       "7  your vandalism to the Matt Shirvington article...  \n",
       "8  sorry if the word nonsense be offensive to you...  \n",
       "9  alignment on this subject and which be contrar...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "Молодец, что используешь лемматизатор WordNetLemmatizer. Но в данном случае он отработал не очень хорошо, и если присмотреться к тексту это хорошо видно. Например, в четвертой строке видим глагол are, но его начальная форма - be. Аналогично в нулевой строке есть глагол made, а его начальная форма make. \n",
    "    \n",
    "Как правило, совершаются следующие ошибки:\n",
    "    \n",
    " - Лемматизация должна производиться по одному слову, а не весь комментарий целиком\n",
    " - Слова должны быть приведены к нижнему регистру\n",
    " - Кроме самого слова в лемматизатор нужно передать дополнительную информацию о части речи слова (POS тег). \n",
    "    \n",
    "    \n",
    "    \n",
    "Ты можешь доработать подход с WordNetLemmatizer или использовать spaCy, там все отрабатывает \"из коробки\". Можешь посмотреть вот эту статью.  \n",
    "\n",
    "\n",
    "https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "    \n",
    "Хочу обратить твое внимание, что код из вышеуказанной статьи выполняется несколько дольше, чем оптимизированный, вот из этого топика\n",
    "    \n",
    "https://stackoverflow.com/questions/50992974/nltk-wordnetlemmatizer-not-lemmatizing-as-expected    \n",
    "    \n",
    "    \n",
    "    \n",
    "Совет - старайся сразу проверять  результаты лемматизации. Например, для предложения\n",
    "    \n",
    "    sentence = \"The striped bats are hanging on their feet for best\"\n",
    "    \n",
    "После лемматизации должен получиться вот такой результат\n",
    "    \n",
    "    \"the strip bat be hang on their foot for best\"    \n",
    "    \n",
    "Если будешь лемматизировать по второму способу, то слово  striped может остаться без изменений, это тоже  нормально (особенность алгоритма).       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Исправлено, использовал spacy для лемматизации\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> 👍 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('Количество')\n",
    "plt.title('Количество токсичных и нетоксичных комментариев')\n",
    "plt.xticks([0, 1], ['Нетоксичный', 'Токсичный'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "Молодец, исследован баланс классов. Это важная информация для задачи классификации.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "    Для категориальных признаком лучше исполользовать столбчатую диаграмму, а гистограмму давай оставим для числовых признаков.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "Напоминаю, что по правилам оформления проектов у графиков должны быть заголовки и подписаны оси (где это уместно).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Исправлено\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> 👍 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143106\n",
      "16186\n"
     ]
    }
   ],
   "source": [
    "class_balance = df['toxic'].value_counts()\n",
    "print(class_balance[0])\n",
    "print(class_balance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_balance[0] / class_balance[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружен явный дисбаланс, где класс с токсичными комментариями меньше почти в 9 раз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на признаки и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143362,)\n",
      "(143362,)\n",
      "(15930,)\n",
      "(15930,)\n"
     ]
    }
   ],
   "source": [
    "features = df['lemmatized_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.1, random_state = 12345, stratify=target)\n",
    "\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Абсолютно согласен с твоим решением выделить 10% на тестовую выборку. Учитывая общий размер данных данной выборки достаточно.\n",
    "    \n",
    "Отдельный \"лайк\" за стратификацию.    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Не стоит делать балансировку - это \"скользкая дорожка\". Это было бы нормально, если бы ты использовал сбалансированную выборку только для обучения модели. Но ведь ты используешь её для кросс-валидации, соответственно и оценку модели ты производишь на сбалансированном валидационном фолде. А оценка метрики f1, полученная на сбалансированной выборке покажет заметно более высокие значения, чем оценка этой же метрики этой же модели, но полученная на исходной, несбаласнированной выборки.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>образец комментария студента</b></font>\n",
    "   \n",
    "Удалил ячейки с кодом, где использовалась балансировка с помощью downsampling-a\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> 👍 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Загружены все описания товаров в сервисе ВикиШоп, произведены операции лемматизации и токенизации текста. Данные разделены на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание корпуса текстов и учет стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LogisticRegression()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365059329538844"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr = cross_val_score(pipeline_lr, features_train, target_train, cv=5, scoring='f1')\n",
    "f1_lr = scores_lr.mean()\n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", RandomForestClassifier(random_state=12345)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'clf__n_estimators' : [10, 30, 60],\n",
    "    'clf__max_depth' : [2, 5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_rf = GridSearchCV(estimator = pipeline_rf,\n",
    "                     param_grid = params_grid,\n",
    "                     scoring = 'f1',\n",
    "                     cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 48s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=12345))]),\n",
       "             param_grid={'clf__max_depth': [2, 5, 10, 15],\n",
       "                         'clf__n_estimators': [10, 30, 60]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GS_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15, 'clf__n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004106778589007964"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_rf = GS_rf.best_score_\n",
    "f1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lgb = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LGBMClassifier(random_state=12345)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_lgb = {\n",
    "    'clf__num_leaves': [31, 50, 80],\n",
    "    'clf__learning_rate': [0.05, 0.1],\n",
    "    'clf__n_estimators': [100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_lgb = GridSearchCV(estimator = pipeline_lgb,\n",
    "                     param_grid = params_grid_lgb,\n",
    "                     scoring = 'f1',\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.731307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.702261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.703250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.679890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.667395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.675388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.741547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.661177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.728548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.746956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.718104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.730446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.696125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.755889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.682270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.727013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.707822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.691412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.813832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.663651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.681955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.703808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.702781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.734143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.717392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.761929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.742048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.851784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.649064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.860096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.780668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.850411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.788339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.802332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.807826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.794872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.819890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.893957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.798512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.042645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.921719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.732793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.929192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.948908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.903191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.949520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.816389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.826419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.954150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.886851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 14567, number of negative: 128795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.109409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 587138\n",
      "[LightGBM] [Info] Number of data points in the train set: 143362, number of used features: 10762\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101610 -> initscore=-2.179463\n",
      "[LightGBM] [Info] Start training from score -2.179463\n",
      "CPU times: total: 1h 21min 39s\n",
      "Wall time: 17min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=12345))]),\n",
       "             param_grid={'clf__learning_rate': [0.05, 0.1],\n",
       "                         'clf__n_estimators': [100, 150],\n",
       "                         'clf__num_leaves': [31, 50, 80]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GS_lgb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.1, 'clf__n_estimators': 150, 'clf__num_leaves': 80}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789805574260013"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_lgb = GS_lgb.best_score_\n",
    "f1_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = [['LinearRegression', f1_lr],\n",
    "            ['RandomForestRegression', f1_rf],\n",
    "            ['LightGBM', f1_lgb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.736506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegression</td>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.778981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1_score\n",
       "0        LinearRegression  0.736506\n",
       "1  RandomForestRegression  0.004107\n",
       "2                LightGBM  0.778981"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(models_info, columns=[\"Model\",\"F1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшее значение f1_score для тестовой выборки оказалось у модели LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка лучшей модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(n_estimators=150, num_leaves=80,\n",
       "                                random_state=12345))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_lgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = GS_lgb.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790633608815427"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test = f1_score(target_test, predictions_test)\n",
    "f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** При проверке модели на тестовой выборке метрика f1 оказалась 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы на проектом выполнены следующие мероприятия:\n",
    "- Загружены и проанализированы описания товаров в интернет-магазине Wikishop.\n",
    "- Подготовлены данные для обучения моделей: произведены лемматизация и токенизация описаний, данные разделены на обучающую и тестовую выборки с использованием стратификации.\n",
    "- Обучены 3 разные модели (LinearRegression, RandomForest, LightGBM), подобраны оптимальные гиперпараметры. \n",
    "- Выбрана наилучшая модель по метрике f1. Ей оказалась модель LightGBM. При проверке качества модели на тестовой выборке метрика f1-score составил 0.79, что входит в пределы порогового значения >0.75."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
