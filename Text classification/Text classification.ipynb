{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\" data-toc-modified-id=\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span><ul class=\"toc-item\"><li><span><a href=\"#–ó–∞–≥—Ä—É–∑–∫–∞-–¥–∞–Ω–Ω—ã—Ö-–∏-–ø–µ—Ä–≤–∏—á–Ω—ã–π-–æ—Å–º–æ—Ç—Ä\" data-toc-modified-id=\"–ó–∞–≥—Ä—É–∑–∫–∞-–¥–∞–Ω–Ω—ã—Ö-–∏-–ø–µ—Ä–≤–∏—á–Ω—ã–π-–æ—Å–º–æ—Ç—Ä-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä</a></span></li><li><span><a href=\"#–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è-–∏-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è-—Ç–µ–∫—Å—Ç–∞\" data-toc-modified-id=\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è-–∏-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è-—Ç–µ–∫—Å—Ç–∞-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞</a></span></li><li><span><a href=\"#–î–∏—Å–±–∞–ª–∞–Ω—Å-–∫–ª–∞—Å—Å–æ–≤\" data-toc-modified-id=\"–î–∏—Å–±–∞–ª–∞–Ω—Å-–∫–ª–∞—Å—Å–æ–≤-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤</a></span></li><li><span><a href=\"#–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ-–Ω–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏-–∏-—Ü–µ–ª–µ–≤–æ–π-–ø—Ä–∏–∑–Ω–∞–∫\" data-toc-modified-id=\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ-–Ω–∞-–ø—Ä–∏–∑–Ω–∞–∫–∏-–∏-—Ü–µ–ª–µ–≤–æ–π-–ø—Ä–∏–∑–Ω–∞–∫-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫</a></span></li></ul></li><li><span><a href=\"#–û–±—É—á–µ–Ω–∏–µ\" data-toc-modified-id=\"–û–±—É—á–µ–Ω–∏–µ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span><ul class=\"toc-item\"><li><span><a href=\"#–°–æ–∑–¥–∞–Ω–∏–µ-–∫–æ—Ä–ø—É—Å–∞-—Ç–µ–∫—Å—Ç–æ–≤-–∏-—É—á–µ—Ç-—Å—Ç–æ–ø-—Å–ª–æ–≤\" data-toc-modified-id=\"–°–æ–∑–¥–∞–Ω–∏–µ-–∫–æ—Ä–ø—É—Å–∞-—Ç–µ–∫—Å—Ç–æ–≤-–∏-—É—á–µ—Ç-—Å—Ç–æ–ø-—Å–ª–æ–≤-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ —É—á–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤</a></span></li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Linear Regression</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#–í—ã–±–æ—Ä-–ª—É—á—à–µ–π-–º–æ–¥–µ–ª–∏\" data-toc-modified-id=\"–í—ã–±–æ—Ä-–ª—É—á—à–µ–π-–º–æ–¥–µ–ª–∏-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>–í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏</a></span></li></ul></li><li><span><a href=\"#–ü—Ä–æ–≤–µ—Ä–∫–∞-–ª—É—á—à–µ–π-–º–æ–¥–µ–ª–∏-–Ω–∞-—Ç–µ—Å—Ç–æ–≤–æ–π-–≤—ã–±–æ—Ä–∫–µ\" data-toc-modified-id=\"–ü—Ä–æ–≤–µ—Ä–∫–∞-–ª—É—á—à–µ–π-–º–æ–¥–µ–ª–∏-–Ω–∞-—Ç–µ—Å—Ç–æ–≤–æ–π-–≤—ã–±–æ—Ä–∫–µ-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ</a></span></li><li><span><a href=\"#–í—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–í—ã–≤–æ–¥—ã-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href=\"#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏\" data-toc-modified-id=\"–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. \n",
    "\n",
    "–í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç:**\n",
    "- –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–µ –º–µ–Ω—å—à–µ 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ó–∞–¥–∞—á–∏ –ø—Ä–æ–µ–∫—Ç–∞:**\n",
    "- –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.\n",
    "- –û–±—É—á–∏—Ç—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. \n",
    "- –í—ã–±—Ä–∞—Ç—å –Ω–∞–∏–ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤—ã–≤–æ–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –Ω–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\–ö–∏—Ä–∏–ª–ª\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\–ö–∏—Ä–∏–ª–ª\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\–ö–∏—Ä–∏–ª–ª\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\–ö–∏—Ä–∏–ª–ª\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0\n",
       "5           5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6           6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7           7  Your vandalism to the Matt Shirvington article...      0\n",
       "8           8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9           9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159292"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Unnamed: 0'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —É–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü Unnamed\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥:** –í –¥–∞—Ç–∞—Å–µ—Ç–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –æ–∫–æ–ª–æ 160 —Ç—ã—Å. —Å—Ç—Ä–æ–∫ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ —Ç–æ–≤–∞—Ä–æ–≤. –ü—Ä–æ–ø—É—Å–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. –í —Å–≤—è–∑–∏ —Å –Ω–µ–Ω–∞–¥–æ–±–Ω–æ—Å—Ç—å—é, —É–¥–∞–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–≤—Ç–æ—Ä—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on their foot for good'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy lemmatizer\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "doc = nlp(sentence)\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_spacy(text):\n",
    "    clear_text = nlp(\" \".join(re.sub(r'[^a-zA-z]', ' ', text).split()))\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in clear_text])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2629d579b26e4b34ae781f8b3c86671c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['lemmatized_text'] = df['text'].progress_apply(lemm_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –¥–ª–∏—Ç—Å—è –¥–æ–ª–≥–æ... –ú–∏–Ω—É—Ç 20-30, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ—â–Ω–æ—Å—Ç–∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞. –ì–æ—Ä–∞–∑–¥–æ –∫–æ–º—Ñ–æ—Ä—Ç–Ω–µ–µ –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏, —á–µ–º —Å–∏–¥–µ—Ç—å –∏ –≥–∞–¥–∞—Ç—å \"–∞ –Ω–µ –∑–∞–≤–∏—Å–ª–∞ –ª–∏ –æ–Ω–∞\", \"–∑–∞–∫–æ–Ω—á–∏—Ç —Ç–æ–ª—å–∫–æ –∫ —É—Ç—Ä—É –∏–ª–∏ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥\"? –ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–æ–≥—Ä–µ—Å—Å -–±–∞—Ä–æ–º –æ—Ç tqdm.\n",
    "    \n",
    "     \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "\n",
    "    data['lemm_text'] = data['text'].progress_apply(lemmafunction)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>–æ–±—Ä–∞–∑–µ—Ü –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "   \n",
    "–î–æ–±–∞–≤–∏–ª –≤–∏–∑—É–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å. –°–ø–∞—Å–∏–±–æ –∑–∞ –Ω–æ–≤—É—é —Ñ–∏—á—É, –Ω–µ –∑–Ω–∞–ª –ø—Ä–æ —Ñ—É–Ω–∫—Ü–∏—é progress_apply\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> ü§ù </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man I m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulation from I as well use the tool wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>COCKSUCKER before you pis around on MY work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>your vandalism to the Matt Shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry if the word nonsense be offensive to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  alignment on this subject and which are contra...      0   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  Explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour I m seem...  \n",
       "2  hey man I m really not try to edit war it s ju...  \n",
       "3  More I can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  \n",
       "5  congratulation from I as well use the tool wel...  \n",
       "6        COCKSUCKER before you pis around on MY work  \n",
       "7  your vandalism to the Matt Shirvington article...  \n",
       "8  sorry if the word nonsense be offensive to you...  \n",
       "9  alignment on this subject and which be contrar...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "–ú–æ–ª–æ–¥–µ—Ü, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä WordNetLemmatizer. –ù–æ –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –æ–Ω –æ—Ç—Ä–∞–±–æ—Ç–∞–ª –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, –∏ –µ—Å–ª–∏ –ø—Ä–∏—Å–º–æ—Ç—Ä–µ—Ç—å—Å—è –∫ —Ç–µ–∫—Å—Ç—É —ç—Ç–æ —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ —á–µ—Ç–≤–µ—Ä—Ç–æ–π —Å—Ç—Ä–æ–∫–µ –≤–∏–¥–∏–º –≥–ª–∞–≥–æ–ª are, –Ω–æ –µ–≥–æ –Ω–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ - be. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –≤ –Ω—É–ª–µ–≤–æ–π —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å –≥–ª–∞–≥–æ–ª made, –∞ –µ–≥–æ –Ω–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ make. \n",
    "    \n",
    "–ö–∞–∫ –ø—Ä–∞–≤–∏–ª–æ, —Å–æ–≤–µ—Ä—à–∞—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –æ—à–∏–±–∫–∏:\n",
    "    \n",
    " - –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å—Å—è –ø–æ –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É, –∞ –Ω–µ –≤–µ—Å—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ü–µ–ª–∏–∫–æ–º\n",
    " - –°–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–∏–≤–µ–¥–µ–Ω—ã –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
    " - –ö—Ä–æ–º–µ —Å–∞–º–æ–≥–æ —Å–ª–æ–≤–∞ –≤ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–∞—Å—Ç–∏ —Ä–µ—á–∏ —Å–ª–æ–≤–∞ (POS —Ç–µ–≥). \n",
    "    \n",
    "    \n",
    "    \n",
    "–¢—ã –º–æ–∂–µ—à—å –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–¥—Ö–æ–¥ —Å WordNetLemmatizer –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å spaCy, —Ç–∞–º –≤—Å–µ –æ—Ç—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç \"–∏–∑ –∫–æ—Ä–æ–±–∫–∏\". –ú–æ–∂–µ—à—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ—Ç —ç—Ç—É —Å—Ç–∞—Ç—å—é.  \n",
    "\n",
    "\n",
    "https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "    \n",
    "–•–æ—á—É –æ–±—Ä–∞—Ç–∏—Ç—å —Ç–≤–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –∫–æ–¥ –∏–∑ –≤—ã—à–µ—É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–ª—å—à–µ, —á–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –≤–æ—Ç –∏–∑ —ç—Ç–æ–≥–æ —Ç–æ–ø–∏–∫–∞\n",
    "    \n",
    "https://stackoverflow.com/questions/50992974/nltk-wordnetlemmatizer-not-lemmatizing-as-expected    \n",
    "    \n",
    "    \n",
    "    \n",
    "–°–æ–≤–µ—Ç - —Å—Ç–∞—Ä–∞–π—Å—è —Å—Ä–∞–∑—É –ø—Ä–æ–≤–µ—Ä—è—Ç—å  —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "    \n",
    "    sentence = \"The striped bats are hanging on their feet for best\"\n",
    "    \n",
    "–ü–æ—Å–ª–µ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –¥–æ–ª–∂–µ–Ω –ø–æ–ª—É—á–∏—Ç—å—Å—è –≤–æ—Ç —Ç–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    \n",
    "    \"the strip bat be hang on their foot for best\"    \n",
    "    \n",
    "–ï—Å–ª–∏ –±—É–¥–µ—à—å –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ –≤—Ç–æ—Ä–æ–º—É —Å–ø–æ—Å–æ–±—É, —Ç–æ —Å–ª–æ–≤–æ  striped –º–æ–∂–µ—Ç –æ—Å—Ç–∞—Ç—å—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —ç—Ç–æ —Ç–æ–∂–µ  –Ω–æ—Ä–º–∞–ª—å–Ω–æ (–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–∞).       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>–æ–±—Ä–∞–∑–µ—Ü –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "   \n",
    "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª spacy –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> üëç </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['toxic'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
    "plt.title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')\n",
    "plt.xticks([0, 1], ['–ù–µ—Ç–æ–∫—Å–∏—á–Ω—ã–π', '–¢–æ–∫—Å–∏—á–Ω—ã–π'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "–ú–æ–ª–æ–¥–µ—Ü, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤. –≠—Ç–æ –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "    –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–º –ª—É—á—à–µ –∏—Å–ø–æ–ª–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±—á–∞—Ç—É—é –¥–∏–∞–≥—Ä–∞–º–º—É, –∞ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –¥–∞–≤–∞–π –æ—Å—Ç–∞–≤–∏–º –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Stop_sign.png/240px-Stop_sign.png\" align=left width=35, heigth=35>\n",
    "<div class=\"alert alert-danger\">\n",
    "–ù–∞–ø–æ–º–∏–Ω–∞—é, —á—Ç–æ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤ —É –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ –ø–æ–¥–ø–∏—Å–∞–Ω—ã –æ—Å–∏ (–≥–¥–µ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>–æ–±—Ä–∞–∑–µ—Ü –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "   \n",
    "–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> üëç </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143106\n",
      "16186\n"
     ]
    }
   ],
   "source": [
    "class_balance = df['toxic'].value_counts()\n",
    "print(class_balance[0])\n",
    "print(class_balance[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_balance[0] / class_balance[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±–Ω–∞—Ä—É–∂–µ–Ω —è–≤–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å, –≥–¥–µ –∫–ª–∞—Å—Å —Å —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏ –º–µ–Ω—å—à–µ –ø–æ—á—Ç–∏ –≤ 9 —Ä–∞–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143362,)\n",
      "(143362,)\n",
      "(15930,)\n",
      "(15930,)\n"
     ]
    }
   ],
   "source": [
    "features = df['lemmatized_text']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size = 0.1, random_state = 12345, stratify=target)\n",
    "\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ê–±—Å–æ–ª—é—Ç–Ω–æ —Å–æ–≥–ª–∞—Å–µ–Ω —Å —Ç–≤–æ–∏–º —Ä–µ—à–µ–Ω–∏–µ–º –≤—ã–¥–µ–ª–∏—Ç—å 10% –Ω–∞ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É. –£—á–∏—Ç—ã–≤–∞—è –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.\n",
    "    \n",
    "–û—Ç–¥–µ–ª—å–Ω—ã–π \"–ª–∞–π–∫\" –∑–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é.    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/ba/Warning_sign_4.0.png\" align=left width=44, heigth=33>\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "–ù–µ —Å—Ç–æ–∏—Ç –¥–µ–ª–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É - —ç—Ç–æ \"—Å–∫–æ–ª—å–∑–∫–∞—è –¥–æ—Ä–æ–∂–∫–∞\". –≠—Ç–æ –±—ã–ª–æ –±—ã –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –±—ã —Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏. –ù–æ –≤–µ–¥—å —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –µ—ë –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –∏ –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏ —Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—à—å –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º —Ñ–æ–ª–¥–µ. –ê –æ—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫–∏ f1, –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –Ω–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ –ø–æ–∫–∞–∂–µ—Ç –∑–∞–º–µ—Ç–Ω–æ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, —á–µ–º –æ—Ü–µ–Ω–∫–∞ —ç—Ç–æ–π –∂–µ –º–µ—Ç—Ä–∏–∫–∏ —ç—Ç–æ–π –∂–µ –º–æ–¥–µ–ª–∏, –Ω–æ –ø–æ–ª—É—á–µ–Ω–Ω–∞—è –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–π, –Ω–µ—Å–±–∞–ª–∞—Å–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\" style=\"background-color:#ead7f7;color:#8737bf\">\n",
    "    <font size=\"3\"><b>–æ–±—Ä–∞–∑–µ—Ü –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞</b></font>\n",
    "   \n",
    "–£–¥–∞–ª–∏–ª —è—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º, –≥–¥–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ —Å –ø–æ–º–æ—â—å—é downsampling-a\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://emojigraph.org/media/apple/check-mark-button_2705.png\" align=left width=33, heigth=33>\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>v2</b> üëç </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥:** –ó–∞–≥—Ä—É–∂–µ–Ω—ã –≤—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Å–µ—Ä–≤–∏—Å–µ –í–∏–∫–∏–®–æ–ø, –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ—Ä–ø—É—Å–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏ —É—á–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LogisticRegression()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365059329538844"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr = cross_val_score(pipeline_lr, features_train, target_train, cv=5, scoring='f1')\n",
    "f1_lr = scores_lr.mean()\n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", RandomForestClassifier(random_state=12345)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'clf__n_estimators' : [10, 30, 60],\n",
    "    'clf__max_depth' : [2, 5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_rf = GridSearchCV(estimator = pipeline_rf,\n",
    "                     param_grid = params_grid,\n",
    "                     scoring = 'f1',\n",
    "                     cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 48s\n",
      "Wall time: 3min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=12345))]),\n",
       "             param_grid={'clf__max_depth': [2, 5, 10, 15],\n",
       "                         'clf__n_estimators': [10, 30, 60]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GS_rf.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 15, 'clf__n_estimators': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004106778589007964"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_rf = GS_rf.best_score_\n",
    "f1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lgb = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LGBMClassifier(random_state=12345)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_lgb = {\n",
    "    'clf__num_leaves': [31, 50, 80],\n",
    "    'clf__learning_rate': [0.05, 0.1],\n",
    "    'clf__n_estimators': [100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_lgb = GridSearchCV(estimator = pipeline_lgb,\n",
    "                     param_grid = params_grid_lgb,\n",
    "                     scoring = 'f1',\n",
    "                     cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.678040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.731307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.702261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.703250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.679890 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.701093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.667395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.675388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.741547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.694028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.661177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.728548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.746956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.718104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.730446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.719396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.696125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.755889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.682270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.727013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.707822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.691412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.813832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.663651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.681955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.703808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.702781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.734143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.717392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.761929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.742048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.851784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.649064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.860096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.780668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.850411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.788339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.802332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.807826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.794872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.819890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.893957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.798512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.042645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.921719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.693076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.732793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.929192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.948908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.903191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.949520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500348\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9306\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11653, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.816389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500895\n",
      "[LightGBM] [Info] Number of data points in the train set: 114689, number of used features: 9376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101605 -> initscore=-2.179515\n",
      "[LightGBM] [Info] Start training from score -2.179515\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.826419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 502780\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9377\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.954150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 500569\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9342\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 103036\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.886851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501066\n",
      "[LightGBM] [Info] Number of data points in the train set: 114690, number of used features: 9322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179429\n",
      "[LightGBM] [Info] Start training from score -2.179429\n",
      "[LightGBM] [Info] Number of positive: 14567, number of negative: 128795\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.109409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 587138\n",
      "[LightGBM] [Info] Number of data points in the train set: 143362, number of used features: 10762\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101610 -> initscore=-2.179463\n",
      "[LightGBM] [Info] Start training from score -2.179463\n",
      "CPU times: total: 1h 21min 39s\n",
      "Wall time: 17min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=12345))]),\n",
       "             param_grid={'clf__learning_rate': [0.05, 0.1],\n",
       "                         'clf__n_estimators': [100, 150],\n",
       "                         'clf__num_leaves': [31, 50, 80]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "GS_lgb.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.1, 'clf__n_estimators': 150, 'clf__num_leaves': 80}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7789805574260013"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_lgb = GS_lgb.best_score_\n",
    "f1_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_info = [['LinearRegression', f1_lr],\n",
    "            ['RandomForestRegression', f1_rf],\n",
    "            ['LightGBM', f1_lgb]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.736506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegression</td>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.778981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1_score\n",
       "0        LinearRegression  0.736506\n",
       "1  RandomForestRegression  0.004107\n",
       "2                LightGBM  0.778981"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(models_info, columns=[\"Model\",\"F1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–∏–ª—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ f1_score –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –æ–∫–∞–∑–∞–ª–æ—Å—å —É –º–æ–¥–µ–ª–∏ LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(n_estimators=150, num_leaves=80,\n",
       "                                random_state=12345))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_lgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = GS_lgb.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.790633608815427"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test = f1_score(target_test, predictions_test)\n",
    "f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥:** –ü—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –º–µ—Ç—Ä–∏–∫–∞ f1 –æ–∫–∞–∑–∞–ª–∞—Å—å 0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ö–æ–¥–µ —Ä–∞–±–æ—Ç—ã –Ω–∞ –ø—Ä–æ–µ–∫—Ç–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è:\n",
    "- –ó–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ Wikishop.\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω—ã –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏–π, –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n",
    "- –û–±—É—á–µ–Ω—ã 3 —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ (LinearRegression, RandomForest, LightGBM), –ø–æ–¥–æ–±—Ä–∞–Ω—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã. \n",
    "- –í—ã–±—Ä–∞–Ω–∞ –Ω–∞–∏–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ –º–µ—Ç—Ä–∏–∫–µ f1. –ï–π –æ–∫–∞–∑–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å LightGBM. –ü—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –º–µ—Ç—Ä–∏–∫–∞ f1-score —Å–æ—Å—Ç–∞–≤–∏–ª 0.79, —á—Ç–æ –≤—Ö–æ–¥–∏—Ç –≤ –ø—Ä–µ–¥–µ–ª—ã –ø–æ—Ä–æ–≥–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è >0.75."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
